{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "80517dbc",
      "metadata": {
        "id": "80517dbc"
      },
      "source": [
        "# Teach an LLM to do additions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aaca18f",
      "metadata": {
        "id": "0aaca18f"
      },
      "source": [
        "The goal of this project is to teach an LLM to do additions, playing only with two parts:\n",
        "* the tokenizer\n",
        "* the positional embedding\n",
        "\n",
        "Both the model and the dataset are fixed.\n",
        "\n",
        "You are allowed to tune the hyperparameters, but this is not the main goal. Depending on the quality of your tokenizer and positional embedding, you may change the number of bits. The initial value of 3 is very small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ae993bb9",
      "metadata": {
        "id": "ae993bb9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "OzGh9ahKF17h",
      "metadata": {
        "id": "OzGh9ahKF17h"
      },
      "outputs": [],
      "source": [
        "number_bits = 2\n",
        "\n",
        "dataset_size = 64_000\n",
        "train_proportion = 0.9\n",
        "\n",
        "log_interval = 200\n",
        "batch_size = 64\n",
        "epochs = 4\n",
        "learning_rate = 8e-4\n",
        "\n",
        "eval_debug = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c054bed",
      "metadata": {
        "id": "6c054bed"
      },
      "source": [
        "## Step 1: Construct a tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "t6aC9uNeIR6C",
      "metadata": {
        "id": "t6aC9uNeIR6C"
      },
      "outputs": [],
      "source": [
        "pad_token=\"[PAD]\"\n",
        "eos_token=\"[EOS]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BMvT0B-MGBnY",
      "metadata": {
        "id": "BMvT0B-MGBnY"
      },
      "source": [
        "### Baseline: character-level tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "g2QiF-otFur3",
      "metadata": {
        "id": "g2QiF-otFur3"
      },
      "outputs": [],
      "source": [
        "class character_level_tokenizer:\n",
        "    \"\"\"\n",
        "    character-level\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.vocab = [str(x) for x in range(10)] + [\"+\", \"=\"] + [pad_token, eos_token]\n",
        "        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n",
        "        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n",
        "        self.ntokens = len(self.vocab)\n",
        "        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n",
        "\n",
        "    def clean(self, text):\n",
        "        \"\"\"\n",
        "        removes all characters not in the vocabulary\n",
        "        \"\"\"\n",
        "        out = re.sub(self.pattern, \"\", text)\n",
        "        return out\n",
        "\n",
        "    def pre_tokenization(self, text):\n",
        "        \"\"\"\n",
        "        character-level\n",
        "        \"\"\"\n",
        "        return [c for c in text]\n",
        "\n",
        "    def encode(self, text):\n",
        "        text_list = self.pre_tokenization(self.clean(text))\n",
        "        return [self.token_to_id[c] for c in text_list]\n",
        "\n",
        "    def decode(self, token_list):\n",
        "        return \"\".join([self.id_to_token[x] for x in token_list])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j3gckvebGGYt",
      "metadata": {
        "id": "j3gckvebGGYt"
      },
      "source": [
        "# Implement your tokenizer here!\n",
        "\n",
        "You can do anything (as long as you do not compute the addition!).\n",
        "Some ideas:\n",
        "* reversing numbers left to right\n",
        "* arranging by groups (of, 2, 3,...)\n",
        "* aligning numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "X080MghX4scF",
      "metadata": {
        "id": "X080MghX4scF"
      },
      "outputs": [],
      "source": [
        "class sum_tokenizer:\n",
        "    \"\"\"\n",
        "    xyz + ab = cde is pre-encoded as (z+b)(y+a)(x+0)=edc to help the LLM learn how to add numbers (in a more sequencial way as we do it)\n",
        "    We see that there is a strong pattern each 5 positions, we will explore this in the positional embedding\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.vocab = [str(x) for x in range(10)] + [\"+\", \"=\", \"(\", \")\"] + [pad_token, eos_token]\n",
        "        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n",
        "        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n",
        "        self.ntokens = len(self.vocab)\n",
        "        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n",
        "\n",
        "\n",
        "    def clean(self, text):\n",
        "        \"\"\"\n",
        "        removes all characters not expected in the LLM tokens (vocab)\n",
        "        \"\"\"\n",
        "        out = re.sub(self.pattern, \"\", text)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def clean_number(self, text):\n",
        "        \"\"\"\n",
        "        removes all non-numeric characters\n",
        "        \"\"\"\n",
        "        pattern_number = [str(x) for x in range(10)]\n",
        "        pattern_number = f\"[^{re.escape(''.join(pattern_number))}]\"\n",
        "        out = re.sub(pattern_number, \"\", text)\n",
        "        return out\n",
        "\n",
        "    def pre_tokenization(self, text):\n",
        "        if (eval_debug):\n",
        "            print(\"pretoken from:\", text)\n",
        "\n",
        "        # input (from 'xyz + ab = cde' to '(z+b)(y+a)(x+0)=edc')\n",
        "        if \"+\" in text:\n",
        "            n_1, n_2 = text.split('+', 1)\n",
        "            n_2, result = n_2.split('=', 1)\n",
        "\n",
        "            # make the same size adding left zeros\n",
        "            while len(n_1) != len(n_2):\n",
        "                if len(n_1) > len(n_2):\n",
        "                    n_2 = \"0\" + n_2\n",
        "                else:\n",
        "                    n_1 = \"0\" + n_1\n",
        "\n",
        "            # write in the good format\n",
        "            n_1 = list(n_1[::-1])\n",
        "            n_2 = list(n_2[::-1])\n",
        "            text = \"\"\n",
        "            for i in range(0, len(n_1)):\n",
        "                text += \"(\" + n_1[i] + \"+\" + n_2[i] + \")\"\n",
        "            text = text + \"=\"\n",
        "            text = text + result[::-1]\n",
        "\n",
        "        # output (only revert from 'cde' to 'edc')\n",
        "        else:\n",
        "            text = text[::-1]\n",
        "\n",
        "        if (eval_debug):\n",
        "            print(\"pretoken to:\", text)\n",
        "\n",
        "        return [c for c in text]\n",
        "\n",
        "    def encode(self, text):\n",
        "        text_list = self.pre_tokenization(self.clean(text))\n",
        "        return [self.token_to_id[c] for c in text_list]\n",
        "\n",
        "    def decode(self, token_list):\n",
        "        text = \"\".join([self.id_to_token[x] if self.id_to_token[x] not in [pad_token, eos_token] else \"\" for x in token_list])\n",
        "\n",
        "        if (eval_debug):\n",
        "            print(\"decoded from:\", text)\n",
        "\n",
        "        # outputs (only undo reversion)\n",
        "        if \"=\" not in text:\n",
        "            if (eval_debug):\n",
        "                print(\"decoded to:\", text[::-1])\n",
        "            return text[::-1]\n",
        "\n",
        "        # inputs (from 'zb,ya,x0=' to 'xyz+ab=')\n",
        "        text, result = text.split(\"=\", 1)\n",
        "        text = list(text)\n",
        "        n_1 = \"\"\n",
        "        n_2 = \"\"\n",
        "        for i in range(len(text)):\n",
        "            if text[i] == \"(\":\n",
        "              n_1 = n_1 + text[i+1]\n",
        "              n_2 = n_2 + text[i+3]\n",
        "        n_1 = n_1[::-1]\n",
        "        n_2 = n_2[::-1]\n",
        "        n_1 = str(int(n_1))\n",
        "        n_2 = str(int(n_2))\n",
        "\n",
        "        if (eval_debug):\n",
        "            print(\"decoded to:\", n_1 + \"+\" + n_2 + \"=\" + result[::-1])\n",
        "\n",
        "        return n_1 + \"+\" + n_2 + \"=\" + result[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "QuCc6jF5F8hK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuCc6jF5F8hK",
        "outputId": "673ab399-44f7-447a-daaf-d79d75e7a08c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = sum_tokenizer()\n",
        "ntokens = tokenizer.ntokens\n",
        "ntokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8FXW2K-1Jd-P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FXW2K-1Jd-P",
        "outputId": "879ad28a-4669-40a4-ccc3-9f3490763edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pretoken from: 14+6=20\n",
            "pretoken to: (4+6)(1+0)=02\n",
            "decoded from: (4+6)(1+0)=02\n",
            "decoded to: 14+6=20\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([12, 4, 10, 6, 13, 12, 1, 10, 0, 13, 11, 0, 2], '14+6=20')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_debug = True\n",
        "prompt = \"14+6=20\"\n",
        "inputs = tokenizer.encode(prompt)\n",
        "inputs, tokenizer.decode(inputs)\n",
        "\n",
        "# for elem in data[:5]:\n",
        "#     print(\"\\n\", elem[0])\n",
        "#     prompt = elem[0]\n",
        "#     inputs = tokenizer.encode(prompt)\n",
        "#     inputs, tokenizer.decode(inputs)\n",
        "#     print(\"\\n\", elem[1])\n",
        "#     prompt = elem[1]\n",
        "#     inputs = tokenizer.encode(prompt)\n",
        "#     inputs, tokenizer.decode(inputs)\n",
        "#     print(\"\\n\", elem)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "491af297",
      "metadata": {
        "id": "491af297"
      },
      "source": [
        "## Step 2: Create a dataset for arithmetic operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "daa90f31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daa90f31",
        "outputId": "7ab71394-f305-4736-d1fa-469ea18177d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('401+347=', '748')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def sample_datapoint(number_bits = 3):\n",
        "    \"\"\"\n",
        "    returns a string containing two random numbers on `number_bits` many bits and their sum.\n",
        "    \"\"\"\n",
        "    a_list = [random.randint(0, 9) for _ in range(number_bits)]\n",
        "    b_list = [random.randint(0, 9) for _ in range(number_bits)]\n",
        "    a_int = int(\"\".join([str(x) for x in a_list]))\n",
        "    b_int = int(\"\".join([str(x) for x in b_list]))\n",
        "    sum_int = a_int + b_int\n",
        "    return (str(a_int) + \"+\" + str(b_int) + \"=\", str(sum_int))\n",
        "\n",
        "sample_datapoint(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b6e861d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6e861d2",
        "outputId": "6079c012-c73c-480e-9094-8a58225d06ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('9+61=', '70'), ('38+35=', '73'), ('51+11=', '62'), ('41+24=', '65')]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = []\n",
        "for _ in range(dataset_size):\n",
        "    data.append(sample_datapoint(number_bits))\n",
        "data[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fee85050",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fee85050",
        "outputId": "15d82958-8cae-48e7-8d3e-df19231f439c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(57600, 6400)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train = data[: int(train_proportion * dataset_size)]\n",
        "data_test = data[int(train_proportion * dataset_size):]\n",
        "\n",
        "len(data_train),len(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37200598",
      "metadata": {
        "id": "37200598"
      },
      "source": [
        "## Step 3: Construct a model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fd7d2eb",
      "metadata": {
        "id": "0fd7d2eb"
      },
      "source": [
        "### Basline: the classical Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "36iVhO9qNU5M",
      "metadata": {
        "id": "36iVhO9qNU5M"
      },
      "outputs": [],
      "source": [
        "# class PositionalEmbedding(nn.Module):\n",
        "#     r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
        "#         The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
        "#         Here, we use sine and cosine functions of different frequencies.\n",
        "#     .. math:\n",
        "#         \\text{PosEmbedder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "#         \\text{PosEmbedder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "#         \\text{where pos is the word position and i is the embed idx)\n",
        "#     Args:\n",
        "#         d_model: the embed dim (required).\n",
        "#         dropout: the dropout value (default=0.1).\n",
        "#         max_len: the max. length of the incoming sequence (default=5000).\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "#         super(PositionalEmbedding, self).__init__()\n",
        "#         self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "#         pe = torch.zeros(max_len, d_model)\n",
        "#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
        "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
        "#         pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "#         self.register_buffer('pe', pe)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         r\"\"\"Inputs of forward function\n",
        "#         Args:\n",
        "#             x: the sequence fed to the positional encoder model (required).\n",
        "#         Shape:\n",
        "#             x: [sequence length, batch size, embed dim]\n",
        "#             output: [sequence length, batch size, embed dim]\n",
        "#         \"\"\"\n",
        "\n",
        "#         x = x + self.pe[:x.size(0), :]\n",
        "#         return self.dropout(x)\n",
        "    \n",
        "\n",
        "# Because we group each pair of digits of the same significance next to each other, \n",
        "# then a good positional encoding could be to give each pair the same positional encoding!\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, repeats = 50, number_bits = 3):\n",
        "        # Create a positional embedding that is periodic in the number of bits used to represent numbers!\n",
        "        # numbers should be consecutive with no double + or double so that this encoding works (i.e clear and clean prompts!)\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.number_bits = number_bits\n",
        "        position = torch.arange(repeats, dtype= torch.float).repeat_interleave(2).unsqueeze(1) # each position is repeated 2 times: [0,0, 1, 1, 2, 2,...]\n",
        "\n",
        "        # Positional encodings\n",
        "        pe = torch.zeros(position.size(0), d_model)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1) # shape (2 * repeats, 1, d_model)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8296ceb2",
      "metadata": {
        "id": "8296ceb2"
      },
      "source": [
        "# Implement your positional embedding here!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0194bbd1",
      "metadata": {},
      "source": [
        "\n",
        "Our input is extremely periodic, with period 5:\n",
        "\n",
        "'xyz + ab = ' is encoded to '(z+b)(z+a)(x+0)='\n",
        "\n",
        "Here I implemented a periodic positional embedding as a sum of decaying sinus funcitons of periods multiple of 5.\n",
        "\n",
        "$pe(dim\\_even) = \\sin(\\frac{2π*pos}{5}) + \\frac{1}{\\sqrt{2}}*\\sin(\\frac{2π*pos}{10}) + \\frac{1}{\\sqrt{3}}*\\sin(\\frac{2π*pos}{20}) + ...$\n",
        "\n",
        "$pe(dim\\_odd) = \\cos(\\frac{2π*pos}{5}) + \\frac{1}{\\sqrt{2}}*\\cos(\\frac{2π*pos}{10}) + \\frac{1}{\\sqrt{3}}*\\cos(\\frac{2π*pos}{20}) + ...$\n",
        "\n",
        "Then, I normalize to ensure it is not too large, using $norm = 1 + (1/2) + (1/3) + ...$\n",
        "\n",
        "This is a good encoding for the case for small number of bits, but it struggles with bigger numbers, due to the dilution (1/n) of bigger periods, making it harder to understand long distance dependency.\n",
        "\n",
        "I have try other positional encodings but I also struggled with being able to increase n_bits. :/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "Zz_kr7L4CwPs",
      "metadata": {
        "id": "Zz_kr7L4CwPs"
      },
      "outputs": [],
      "source": [
        "class PeriodicPositionalEmbedding(nn.Module):\n",
        "    r\"\"\"Positional encodings with a fixed periodicity of 5: '(.+.)(.+.)(.+.)=...'\n",
        "        This version explicitly models periodicity based on given periods multiple of 5 (e.g., 5, 10, 20).\n",
        "\n",
        "        Args:\n",
        "            d_model: the embedding dimension\n",
        "            max_len: maximum sequence length\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PeriodicPositionalEmbedding, self).__init__()\n",
        "        self.periods = [5, 10, 20]\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) # (max_len, 1)\n",
        "\n",
        "        # periodic encoding (periods multiple of 5 from the structure \"(.,.)(.,.)(.,.)=...\")\n",
        "        norm = 0\n",
        "        for i in range(len(self.periods)):\n",
        "            omega = 2 * math.pi * position / self.periods[i]\n",
        "            pe[:, 0::2] += torch.sin(position * omega) / ((i+1)**0.5)\n",
        "            pe[:, 1::2] += torch.cos(position * omega) / ((i+1)**0.5)\n",
        "            norm += 1 / (i+1)\n",
        "        pe /= norm\n",
        "\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs:\n",
        "            x: the sequence add to the positional encodding of shape [sequence length, batch size, embed dim]\n",
        "        Outputs:\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        \"\"\"\n",
        "\n",
        "        return (x + self.pe[:x.size(0), :, :]).to(x.device)  # Match input sequence length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "XidcSv8ZvS2x",
      "metadata": {
        "id": "XidcSv8ZvS2x"
      },
      "outputs": [],
      "source": [
        "# Visualize the Positional Embeddings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "embed_dim = 16\n",
        "pos_enc = PeriodicPositionalEmbedding(d_model=embed_dim)\n",
        "\n",
        "pe_values = pos_enc.pe[:20, 0, :].detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "kkQM3Osqx6qv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "kkQM3Osqx6qv",
        "outputId": "0d7e02ac-5aa5-4e6f-dbf8-f0a0b401332a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a heatmap for the positional encodings\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(pe_values, cmap=\"coolwarm\", cbar=True, xticklabels=5, yticklabels=5)\n",
        "\n",
        "plt.xlabel(\"Embedding Dimension\")\n",
        "plt.ylabel(\"Position\")\n",
        "plt.title(\"Periodic Positional Encoding\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98707ce",
      "metadata": {},
      "source": [
        "# Transformer and Longformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4eb278ab",
      "metadata": {
        "id": "4eb278ab"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Transformer):\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__(d_model=ninp,\n",
        "                                               nhead=nhead,\n",
        "                                               dim_feedforward=nhid,\n",
        "                                               num_encoder_layers=nlayers)\n",
        "        self.input_emb = nn.Embedding(ntoken, ninp)\n",
        "        self.pos_encoder = PeriodicPositionalEmbedding(ninp, dropout)\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.ninp = ninp\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.bias)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        return torch.log(torch.tril(torch.ones(sz,sz)))\n",
        "\n",
        "    def forward(self, src):\n",
        "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "        self.src_mask = mask\n",
        "        print(\"src.shape\", src.shape)\n",
        "\n",
        "        src = self.input_emb(src) * math.sqrt(self.ninp)\n",
        "        print(\"input_emb.shape\", src.shape)\n",
        "        src = self.pos_encoder(src)\n",
        "        print(\"pos_encoder.shape\", src.shape)\n",
        "        output_enc = self.encoder(src, mask=self.src_mask)\n",
        "        print(\"encoder.shape\", output_enc.shape)\n",
        "        output_dec = self.decoder(output_enc)\n",
        "        print(\"decoder.shape\", output_dec.shape)\n",
        "        return F.log_softmax(output_dec, dim=-1), output_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "42f9d1ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42f9d1ee",
        "outputId": "2727218b-8c95-4bc0-dafd-2ebdc91bb515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "33c4fa17",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (embedding): Embedding(16, 128)\n",
              "  (position_embedding): PeriodicPositionalEmbedding()\n",
              "  (layers): ModuleList(\n",
              "    (0-7): 8 x TransformerBlock(\n",
              "      (attention): MultiHeadSelfAttention(\n",
              "        (matrix_Q): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (matrix_K): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (matrix_V): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (linear_out): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=128, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers_from_scratch import Longformer, Transformer\n",
        "\n",
        "vocab_size = ntokens\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ffn_dim = 128 \n",
        "num_layers = 8\n",
        "max_len = 128\n",
        "dim_head = 64\n",
        "dim_value = 64\n",
        "dim_query = 64\n",
        "\n",
        "window_size = 3\n",
        "dilation=1\n",
        "\n",
        "\n",
        "transformer = Transformer(vocab_size, embed_dim, num_heads, ffn_dim, num_layers, max_len, V_dim=dim_value, Q_dim=dim_query, positional_embedding=PeriodicPositionalEmbedding)\n",
        "# longformer = Longformer(vocab_size, embed_dim, num_heads, ffn_dim, num_layers, max_len, V_dim=dim_value, Q_dim=dim_query, window_size=window_size, dilation=dilation,positional_embedding=PeriodicPositionalEmbedding) \n",
        "\n",
        "transformer.to(device)\n",
        "# longformer.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1d568cc4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d568cc4",
        "outputId": "300bfdab-59da-4019-ff06-6126c8c5c64c"
      },
      "outputs": [],
      "source": [
        "# model = TransformerModel(ntoken = ntokens,\n",
        "#                          ninp = 128,\n",
        "#                          nhead = 16,\n",
        "#                          nhid = 64,\n",
        "#                          nlayers = 8)\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8f2f06e0",
      "metadata": {
        "id": "8f2f06e0"
      },
      "outputs": [],
      "source": [
        "# def generate(model, prompts, new_tokens = 5):\n",
        "#     input_tensor = prompts # (length_prompts, batch_size)\n",
        "#     input_tensor = input_tensor.to(device)\n",
        "#     for _ in range(new_tokens):\n",
        "#         # print(input_tensor.shape)\n",
        "#         output = model(input_tensor) # (length_prompts, batch_size, ntokens)\n",
        "#         # print(\"output\", output.shape, output)\n",
        "#         # breakpoint()\n",
        "#         last_output = output[-1,:,:] # (batch_size, ntokens)\n",
        "#         token = torch.argmax(last_output, -1).view((1,-1)) # (1, batch_size)\n",
        "#         input_tensor = torch.cat((input_tensor, token), 0)\n",
        "#     return input_tensor\n",
        "\n",
        "def generate(model, prompts, new_tokens = 5):\n",
        "    input_tensor = prompts # (length_prompts, batch_size)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "    input_tensor = input_tensor.permute(1,0) # (batch_size, length_prompts)\n",
        "    for _ in range(new_tokens):\n",
        "        # print(\"input\", input_tensor.shape)\n",
        "        output = model(input_tensor) # (batch_size, length_prompts, ntokens)\n",
        "        # print(\"output\", output.shape)\n",
        "        last_output = output[:, -1,:] # (batch_size, ntokens)\n",
        "        token = torch.argmax(last_output, -1).view((-1,1)) # (batch_size, 1)\n",
        "        # print(\"token\", token.shape)\n",
        "        input_tensor = torch.cat((input_tensor, token), 1) # (batch_size, length_prompts + 1)\n",
        "    return input_tensor.permute(1,0) # (length_prompts + new_tokens, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "de5ea2db",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 64])\n",
            "torch.Size([25, 64])\n"
          ]
        }
      ],
      "source": [
        "model = transformer\n",
        "model.eval()\n",
        "\n",
        "batch_size=64\n",
        "seq_len = 20\n",
        "sample_input = torch.randint(0, vocab_size, (seq_len, batch_size)).to(device)\n",
        "output = generate(model, sample_input)\n",
        "print(sample_input.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d76d1b19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d76d1b19",
        "outputId": "84496b56-1266-400a-cc39-ed7fff38bc73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pretoken from: 2+3=\n",
            "pretoken to: (2+3)=\n",
            "decoded from: (2+3)=6=6=6\n",
            "decoded to: 2+3=6=6=6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[12,  2, 10,  3, 13, 11,  6, 11,  6, 11,  6]]), '2+3=6=6=6')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"2+3=\"\n",
        "prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
        "output = generate(model, prompt_tensor).view((1,-1))\n",
        "output, tokenizer.decode(output.tolist()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "00954ddc",
      "metadata": {
        "id": "00954ddc"
      },
      "outputs": [],
      "source": [
        "def pad(token_list, type_list = \"prompts\"):\n",
        "    max_length = max([len(x) for x in token_list])\n",
        "    out = []\n",
        "    for x in token_list:\n",
        "        if type_list == \"prompts\":\n",
        "            out.append([tokenizer.token_to_id[pad_token]] * (max_length - len(x)) + x)\n",
        "        if type_list == \"answers\":\n",
        "            out.append(x + [tokenizer.token_to_id[eos_token]] + [tokenizer.token_to_id[pad_token]] * (max_length - len(x)))\n",
        "    return out, max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "2c84beab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c84beab",
        "outputId": "c0fe1f8f-0468-4a2f-ff37-94115b430b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1+1=', '21+35='] ['2', '56']\n"
          ]
        }
      ],
      "source": [
        "eval_debug = False\n",
        "\n",
        "prompts = [tokenizer.encode(\"1+1=\"), tokenizer.encode(\"21+35=\")]\n",
        "answers = [tokenizer.encode(\"2\"), tokenizer.encode(\"56\")]\n",
        "padded_prompts, _ = pad(prompts, \"prompts\")\n",
        "padded_answers, _ = pad(answers, \"answers\")\n",
        "padded_prompts, padded_answers\n",
        "print([tokenizer.decode(p) for p in padded_prompts], [tokenizer.decode(p) for p in padded_answers])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "264f9227",
      "metadata": {
        "id": "264f9227"
      },
      "outputs": [],
      "source": [
        "def get_batch(split, i):\n",
        "    data = data_train if split == 'train' else data_test\n",
        "    prompts = [tokenizer.encode(data[i][0]) for i in range(i, i + batch_size)]\n",
        "    padded_prompts, length_prompts = pad(prompts, \"prompts\")\n",
        "    answers = [tokenizer.encode(data[i][1]) for i in range(i, i + batch_size)]\n",
        "    padded_answers, length_answers = pad(answers, \"answers\")\n",
        "    X = torch.stack([torch.tensor(x) for x in padded_prompts], 1)\n",
        "    Y = torch.stack([torch.tensor(x) for x in padded_answers], 1)\n",
        "    return X, Y, length_prompts, length_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "91e281ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e281ad",
        "outputId": "9daf9830-4212-4181-fb58-fbe2fc4d26e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([11, 64]), torch.Size([4, 64]), 11, 3)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, Y, length_prompts, length_answers = get_batch(\"train\", 243)\n",
        "X.shape, Y.shape, length_prompts, length_answers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "113e1fd1",
      "metadata": {
        "id": "113e1fd1"
      },
      "source": [
        "## Step 4: Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1cfcd10a",
      "metadata": {
        "id": "1cfcd10a"
      },
      "outputs": [],
      "source": [
        "def evaluate():\n",
        "    # Turn on evaluation mode disables dropout.\n",
        "    model.eval()\n",
        "    correct = 0.\n",
        "    with torch.no_grad():\n",
        "        for batch, i in enumerate(range(0, len(data_test)//4 - 1, batch_size)):\n",
        "            # print(\"batch\", i)\n",
        "            prompts, target_answers, length_prompts, length_answers = get_batch(\"test\", i)\n",
        "            prompts = prompts.to(device) # (length_prompts, batch_size)\n",
        "            target_answers = target_answers.to(device) # (length_answers + 1, batch_size)\n",
        "            output = generate(model, prompts, length_answers + 1) # (length_prompts + length_answers + 1, batch_size)\n",
        "            answers_tokens = output[length_prompts:, :] # (length_answers + 1, batch_size), contains tokens\n",
        "            equality_test = answers_tokens == target_answers # (length_answers + 1, batch_size), contains boolean values\n",
        "            correct += torch.all(equality_test, axis=0).float().sum()\n",
        "        accuracy = correct / len(data_test)\n",
        "    return accuracy.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ac335b05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac335b05",
        "outputId": "6019ab27-80be-4357-9a31-f29d142b464f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_debug = False\n",
        "evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c54061a",
      "metadata": {
        "id": "4c54061a"
      },
      "source": [
        "## Step 4: Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3638a75d",
      "metadata": {
        "id": "3638a75d"
      },
      "outputs": [],
      "source": [
        "def train_epoch():\n",
        "    model.train()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    for batch, i in enumerate(range(0, len(data_train) - 1, batch_size)):\n",
        "        prompts, target_answers, length_prompts, length_answers = get_batch(\"train\", i)\n",
        "        prompts = prompts.to(device) # (length_prompts, batch_size)\n",
        "        target_answers = target_answers.to(device) # (length_answers, batch_size)\n",
        "        input_tensor = torch.cat((prompts, target_answers), 0) # (length_prompts + length_answers, batch_size)\n",
        "        # print(\"input_tensor.shape\", input_tensor.shape)\n",
        "        input_tensor = input_tensor.permute(1,0) # (batch_size, length_prompts + length_answers)\n",
        "        model.zero_grad()\n",
        "        output = model(input_tensor) # (batch_size, length_prompts + length_answers, , ntokens)\n",
        "        output = output.permute(1,0,2) # (length_prompts + length_answers, batch_size, ntokens)\n",
        "        # print(\"output.shape\", output.shape)\n",
        "        output_answers = output[length_prompts-1:-1,:,:].reshape(-1, ntokens) # (length_answers * batch_size, ntokens)\n",
        "        target_answers = target_answers.view(-1)\n",
        "        loss = F.cross_entropy(output_answers, target_answers)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.2f} | perplexity {:8.2f}'.format(batch, len(data_train) // batch_size,\n",
        "                                                                                                        elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def train():\n",
        "    best_test_accuracy = None\n",
        "    test_accuracy = evaluate()\n",
        "    print('-' * 89)\n",
        "    print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n",
        "    print('-' * 89)\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train_epoch()\n",
        "        test_accuracy = evaluate()\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the test accuracy is the best we've seen so far.\n",
        "        if not best_test_accuracy or test_accuracy < best_test_accuracy:\n",
        "            with open(\"arithmetic.pt\", 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_test_accuracy = test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4e2a8490",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2a8490",
        "outputId": "c22a2614-e93b-4147-ca29-750aa856c7e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| initialisation | test accuracy  0.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   200/  900 batches | ms/batch 178.64 | loss  1.15 | perplexity     3.17\n",
            "|   400/  900 batches | ms/batch 192.52 | loss  1.04 | perplexity     2.83\n",
            "|   600/  900 batches | ms/batch 342.57 | loss  1.28 | perplexity     3.60\n",
            "|   800/  900 batches | ms/batch 577.28 | loss  1.23 | perplexity     3.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 326.56s | test accuracy  0.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   200/  900 batches | ms/batch 737.69 | loss  1.14 | perplexity     3.12\n",
            "|   400/  900 batches | ms/batch 677.11 | loss  1.36 | perplexity     3.89\n",
            "|   600/  900 batches | ms/batch 781.29 | loss  1.55 | perplexity     4.73\n",
            "|   800/  900 batches | ms/batch 1004.38 | loss  1.59 | perplexity     4.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 747.81s | test accuracy  0.00\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m eval_debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train()\n",
            "Cell \u001b[0;32mIn[28], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     40\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 41\u001b[0m     train_epoch()\n\u001b[1;32m     42\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m evaluate()\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m89\u001b[39m)\n",
            "Cell \u001b[0;32mIn[28], line 20\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m target_answers \u001b[38;5;241m=\u001b[39m target_answers\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output_answers, target_answers)\n\u001b[0;32m---> 20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/anaconda3/envs/sql_jupyter/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    628\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/sql_jupyter/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/sql_jupyter/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "eval_debug=False\n",
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "56d9d440",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56d9d440",
        "outputId": "63ce7a34-fc1f-4a41-9985-bf3a9838f621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46+26=1\t actual result: 72\n",
            "66+70=11\t actual result: 136\n",
            "83+96=11\t actual result: 179\n",
            "29+62=1\t actual result: 91\n",
            "99+32=11\t actual result: 131\n",
            "5+7=1\t actual result: 12\n",
            "74+25=1\t actual result: 99\n",
            "34+58=1\t actual result: 92\n",
            "75+50=11\t actual result: 125\n",
            "33+67=11\t actual result: 100\n",
            "52+75=11\t actual result: 127\n",
            "54+8=1\t actual result: 62\n",
            "17+43=1\t actual result: 60\n",
            "34+94=11\t actual result: 128\n",
            "35+61=1\t actual result: 96\n",
            "9+66=1\t actual result: 75\n",
            "90+34=11\t actual result: 124\n",
            "5+67=1\t actual result: 72\n",
            "56+93=11\t actual result: 149\n",
            "23+7=1\t actual result: 30\n"
          ]
        }
      ],
      "source": [
        "eval_debug = False\n",
        "model.eval()\n",
        "\n",
        "for i in range(20):\n",
        "    prompt, answers = data_test[i]\n",
        "    prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
        "    output = generate(model, prompt_tensor, len(answers)).view((1,-1))\n",
        "    print(tokenizer.decode(output.tolist()[0]) + \"\\t actual result: \" + answers)\n",
        "\n",
        "eval_debug = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qJ9IOZu8Xo4Y",
      "metadata": {
        "id": "qJ9IOZu8Xo4Y"
      },
      "source": [
        "## Probing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78be1213",
      "metadata": {
        "id": "78be1213"
      },
      "source": [
        "This is just for fun..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yomPfirhXkLb",
      "metadata": {
        "id": "yomPfirhXkLb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "train_size = 1000\n",
        "test_size = 100\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def data_probing(size):\n",
        "    X = []\n",
        "    y = np.zeros(size)\n",
        "    for i in range(size):\n",
        "        input = torch.tensor(tokenizer.encode(data[i][0])).view((-1, 1)).to(device)\n",
        "        _, output = model(input)\n",
        "        output = output[-1,:,:].flatten()\n",
        "        # determine whether there was a carry in the result:\n",
        "        carry = len(data[i][1]) > len(data[i][0]) / 2\n",
        "        X.append(output.cpu().detach().numpy())\n",
        "        y[i] = carry\n",
        "    return np.array(X), y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QGmfXVxkppfP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGmfXVxkppfP",
        "outputId": "6c7ebd2e-8760-4280-f7e4-871a831e80d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.99"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, y_train = data_probing(train_size)\n",
        "X_test, y_test = data_probing(test_size)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "reg = LogisticRegression()\n",
        "reg.fit(X_train,y_train)\n",
        "reg.score(X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sql_jupyter",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
